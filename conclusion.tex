%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}



We found that using the Lasso and Ridge methods over the OLS on Franke data did not have much benefits on the MSE. But for the terrain data we got a much better with fit with the regularization parameter. This could be because the Franke function is a smooth and easy function to fit and the terrain data can have a much more complex shape. We also found that for the Franke function bootstrapping and k-fold resampling decreased the total error of the model up to certain polynomial degrees where the variance got exponentially higher because of overfitting. This is because when working with a smaller dataset, overfitting will happen sooner. For the Lasso and Ridge method we found that the $\beta$-parameters was smaller with Ridge than Lasso. This can be seen from the cost-function of each of the methods as the Lasso has the 1-norm and Ridge has the 2-norm. This makes Ridge regularize the $\beta$-parameters more.
