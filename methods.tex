%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Method}
%%MOST IMPORTANT FOR METHOD (or results): Put in exact parameters used to produce plots so that a reader can reproduce it. %%

%%On how we implemented: pseudo-code and algos
%Maybe section about using SVD for inverting matrix, or maybe section on SVD in theory

%scaling of data. Why we did or didn't scale. Critical discussion of this.

%Mention train/test split, 2/3 or 4/5 split is usual. Mention that this is usual and then what we used. Where exactly to mention this? May need to restructure method section a bit.

\subsection{Datasets}
Our data was generated from a random uniform distribution in the interval [0,
1]. Two arrays was generated at random, with each containing n=20 data points. 
These arrays, x and y was combined in two mesh grids, X and Y each of size n x n. Thus, our
total dataset consisted of 400 data points. Before any fitting was done on the
data the mesh rids was reshaped into one dimensional arrays.  

\subsubsection{Franke Function}
%What is it
%How did we implement it
%Why did we implement it
%Any testing to know its working correctly? (I think not needed)

The Franke Function was used to test and validate our models. 
The Franke function is a waited sum of four exponentials and takes two
arguments as input: 
\begin{align*}
    \label{eq:franke_function} 
    f(x,y) &= \frac{3}{4}exp\left(-\frac{(9x-2)^2}{4}-\frac{(9y-2)^2}{4} \right)
    + \frac{3}{4}exp\left(-\frac{(9x+1)^2}{49}-\frac{(9y+1)}{10} \right) \\
           &+ \frac{1}{2}exp\left(-\frac{(9x-7)^2}{4}-\frac{(9y-3)^2}{4}
           \right)-\frac{1}{5}exp(-(9x-4)^2-(9y-7)^2)
\end{align*}
This function is widely used for testing of different fitting algorithms. 
Before we applied our fitting algorithms on the terrain data, we used this function
to test and validate that our own developed algorithms worked properly.    

Random normal distributed noise with an amplitude of 0.2, zero mean and a
standard deviation of 1 was added to the data generated from the Franke
function. Our data was split in train and test data, with $20\%$ preserved for
testing purposes. Sklearn's trian\_test\_split function was used for splitting
of the data. In order to keep the dataset consistent between different runs, a
random seed generator was used. Our training data was fitted to polynomials up
to degree 12 in x and y. 



\subsubsection{Terrain data}
%How did we implement it
%Where did we find this
%Why do we use it

The data is from the Oslo area. The specific radar map we are looking at can be downloaded from \href{https://image_link.com}{DIREKTE LINK TIL BILDET}. If the link is outdated, the information of the image location can be found in table \ref{tab:radar_data}. It's from the SRTM mission in February of 2000 with entity ID SRTM1N59E010V3. The data has a resolution of one arc-sec, which gives each pixel a resolution of 30m. 

\begin{table}
    \centering
    \caption{Corner positions of Oslo radar topography data taken in the SRTM mission in the year 2000.}  
    \label{tab:radar_data}
    \begin{tabular}{|c|c|}
    	\hline
    	Corner & Position\\
    	\hline
    	NW & Lat 60\degree 00'00"N, Long 10\degree 00'00"E\\
	\hline
	NE & Lat 60\degree 00'00"N, Long 11\degree 00'00"E\\
	\hline
	SE & Lat 59\degree 00'00"N, Long 11\degree 00'00"E\\
	\hline
	SW & Lat 59\degree 00'00"N, Long 10\degree 00'00"E\\
	\hline
    \end{tabular} 
\end{table}



\subsection{Error estimation}
%Maybe something about implementation of this
To assess the accuracy of our models we will use the mean squared error
$$
MSE(\boldsymbol{y},\tilde{\boldsymbol{y}}) = \frac{1}{n}
\sum_{i=0}^{n-1}(y_i-\tilde{y}_i)^2,
$$
where n is the number of datapoints. This measures the difference between the model value and the actual value. And we will use the score function
$$
R^2(\boldsymbol{y}, \tilde{\boldsymbol{y}}) = 1 - \frac{\sum_{i=0}^{n - 1} (y_i - \tilde{y}_i)^2}{\sum_{i=0}^{n - 1} (y_i - \bar{y})^2},
$$
which is in essence just one minus the MSE in this case, but can be more advanced in other cases. We use this to give a score to the model.

\subsection{Linear regression}
%Something about how we implemented this. Maybe a bit more text here also
For the design matrix we used what is called a Vandermonde design matrix, a matrix for polynomial linear regression
\begin{center}
$\boldsymbol{X}=
\begin{bmatrix} 
1 & x_{0}&x_{0}^{2}&\dots &x_{0}^{p-1}
\\1&x_{1}&x_{1}^{2}&\dots &x_{1}^{p-1}
\\1&x_{2}&x_{2}^{2}&\dots &x_{2}^{p-1}
\\ \vdots &\vdots &\vdots &\ddots &\vdots \\
1&x_{n-1}&ax_{n-1}^{2}&\dots &x_{n-1}^{p-1}
\end{bmatrix}
$
\end{center}

random seed generator was used. 

\subsubsection{Desing matrix}

Our training data was fitted to polynomials up
to degree 12 in x and y. Thus, a design matrix of the form:
\begin{equation*}
    X = 
    \begin{bmatrix}

        1 & x_{0} & y_0 & x_{0}^{2} & x_0 y_0 & y^2 & \dots &y_{0}^{p} \\
        1 & x_{1} & y_1 & x_{1}^{2} & x_1 y_1 & y^2 & \dots &y_{1}^{p} \\
        1 & x_{2} & y_2 & x_{2}^{2} & x_2 y_2 & y^2 & \dots &y_{2}^{p} \\
        \vdots &\vdots &\vdots &\vdots &\vdots & \vdots & \ddots & \vdots \\
        1&x_{n-1} & y_{n-1} & x_{n-1}^2 & x_{n-1} y_{n-1} & y_{n-1}^2 & \dots &y_{n-1}^{p}, 
    \end{bmatrix}
\end{equation*}
was used for OLS-, Ridge- and Lasso regression
The following code snippet was used to generate our Design matrix: 
\begin{lstlisting}[language=Python]
for i in range(1,p+1):
    q = int((i)*(i+1)/2)
    for k in range(i+1):
        X[:,q+k] = (x**(i-k))*(y**k)
return X
\end{lstlisting}

\begin{lstlisting}
FUNCTION create_X(x, y, n)
	X = array(size p+1, size n)
	FOR i = 1 TO i = p
		q = int((i)*(i+1)/2)
		FOR k = 0 TO k = i
			X[:,q+k] = (x**(i-k))*(y**k)
		ENDFOR
	ENDFOR
return X
ENDFUNCTION
\end{lstlisting}

, where p is the polynomial degree and X is the Deign matrix. 
In order to reduce the number of computations, we generated one Design matrix
with number of features corresponding to the maximum polynomial degree $p_{max}
= 12$. This matrix has l features including the intercept given by the
equation: 
\begin{equation*}
        l(p) = int(((p+1)*(p+2)/2))		
\end{equation*}
In order to fit the lower order polynomials this matrix was sliced in the
following way:
\begin{equation*}
    X_{\text{train}}[:,l(p)] 
\end{equation*}

  
% XXX: added y terms to matrix
% XXX: Changed from poly p-1 to p
% %We used the Vandermonde design matrix for a linear regression polynomial fit. No point in having a theory section about this.
% \begin{center}
% $V=
% \begin{bmatrix} 
% 1 & x_{0}&x_{0}^{2}&\dots &x_{0}^{p-1}
% \\1&x_{1}&x_{1}^{2}&\dots &x_{1}^{p-1}
% \\1&x_{2}&x_{2}^{2}&\dots &x_{2}^{p-1}
% \\ \vdots &\vdots &\vdots &\ddots &\vdots \\
% 1&x_{n-1}&ax_{n-1}^{2}&\dots &x_{n-1}^{p-1}
% \end{matrix}
% $
% \end{center}




\subsection{Regression methods}
Three different regression methods was applied to the Franke data and terrain
data.  
\subsubsection{OLS}
%%OLS
%How did we implement it
%Why did we implement it
%Did we do any testing
The optimal values for beta with OLS regression $\hat{\bm{\beta}  }_{OLS}$ was
calculated from equation
\eqref{eq:beta_OLS}. The solution only exist when $(\bm{X}^T \bm{X})$ is
invertible. To circumvent this problem we used numpy's pseudo inverse, to invert
the matrix.

Our own OLS method was compared with Sklearn's method
(sklearn.linear\_model.LinearRegression). For the same training data, without
any re-sampling. Both methods agrees up to polynomial fits of degree nine.  

\subsubsection{Ridge}
%%Ridge
%How did we implement it
%Why did we implement it
%Did we do any testing
In the case of Ridge regression we introduced an array of regularization
parameters $\lambda = [10^{-6}, 10^{-5}, \hdots, 10^{1}]$. The optimal values
of beta with ridge regression $\hat{\bm{\beta } } _{Ridge} $ was calculated
from equation \eqref{eq:beta_ridge}. 

\subsubsection{Lasso}
%%Lasso
%How did we implement it
%Why did we implement it
%Did we do any testing
The same regularization parameters as used for Ridge regression was used to find the
optimal values for beta with Lasso regression, $\hat{\bm{\beta } } _{Lasso} $. We did not develop our
own algorithm for Lasso regression. Insted we used the function provided by the
sklearn python module.  

\subsection{Resampling}
%%Bootstrap
%How did we implement it
%Why did we implement it
%Did we do any testing

%%Cross-validation
%How did we implement it
%Why did we implement it
%Did we do any testing


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Testing}
\begin{table}
    \centering
    \caption{Determinant of $(X^T_{train}X_{train})$ with respect to polynomial
    degree}  
    \begin{tabular}{|c|c|}
        \hline
        Polynomial degree & $det(X_{train}^T X_{train})$  \\
        \hline
        1 & 208035.65\\
        \hline
        2 & 891473.68\\
        \hline
        3 & 99.34\\
        \hline
        4 & 7.91-10 \\
        \hline
        5 & 8.58-31 \\
        \hline
        6 & 1.92-64 \\
        \hline
        7 & 1.13-113 \\
        \hline
        8 & 5.28-181 \\
        \hline
        9 & 2.21-269 \\
        \hline
        10 & 0.0 \\
        \hline
        11 & -0.0 \\
        \hline
        12 & 0.0 \\
        \hline
         
    \end{tabular} 
\end{table}




%THIS IF FROM THE LECTURE NOTES. BUT ABIT EXTENSIVE. MIGHT NOT NEED IT
\begin{comment}
How to set up the cross-validation for Ridge and/or Lasso

* Define a range of interest for the penalty parameter.

* Divide the data set into training and test set comprising samples $\{1, \ldots, n\} \setminus i$ and $\{ i \}$, respectively.

* Fit the linear regression model by means of ridge estimation  for each $\lambda$ in the grid using the training set, and the corresponding estimate of the error variance $\boldsymbol{\sigma}_{-i}^2(\lambda)$, as

\begin{align*}
\boldsymbol{\beta}_{-i}(\lambda) & =  ( \boldsymbol{X}_{-i, \ast}^{T}
\boldsymbol{X}_{-i, \ast} + \lambda \boldsymbol{I}_{pp})^{-1}
\boldsymbol{X}_{-i, \ast}^{T} \boldsymbol{y}_{-i}
\end{align*}

* Evaluate the prediction performance of these models on the test set by $[y_i, \boldsymbol{X}_{i, \ast}; \boldsymbol{\beta}_{-i}(\lambda), \boldsymbol{\sigma}_{-i}^2(\lambda)]$. Or, by the prediction error $|y_i - \boldsymbol{X}_{i, \ast} \boldsymbol{\beta}_{-i}(\lambda)|$, the relative error, the error squared or the R2 score function.

* Repeat the first three steps  such that each sample plays the role of the test set once.

* Average the prediction performances of the test sets at each grid point of the penalty bias/parameter. It is an estimate of the prediction performance of the model corresponding to this value of the penalty parameter on novel data. It is defined as

\begin{align*}
\frac{1}{n} \sum_{i = 1}^n \log\{L[y_i, \mathbf{X}_{i, \ast}; \boldsymbol{\beta}_{-i}(\lambda), \boldsymbol{\sigma}_{-i}^2(\lambda)]\}.
\end{align*}
\end{comment}


\subsubsection{Terrain data}
%How did we implement it
%Where did we find this
%Why do we use it

\subsection{Error estimation}
%%Mean squared error
%What is it
%Why do we use it

%%R^2
%What is it
%Why do we use it
